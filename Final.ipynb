{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da7a0779-7073-40f1-9ace-cd14cb536825",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 01:48:37.501 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /opt/anaconda3/lib/python3.12/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-04-09 01:48:37.677 Session state does not function when running a script without `streamlit run`\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./lib')  # for custom modules if any\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "from PIL import Image\n",
    "import torch\n",
    "import kornia as K\n",
    "import kornia.feature as KF\n",
    "\n",
    "# Import custom SIFT pipeline\n",
    "from sift_functions import generate_image_pyramid, calculate_dog, SIFT_feature_detection\n",
    "from helper_functions import quick_resize\n",
    "from image_stitcher import convert_keypoints_to_cv2, get_descriptors, match_keypoints\n",
    "\n",
    "# Load LoFTR model\n",
    "@st.cache_resource\n",
    "def load_loftr():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = KF.LoFTR(pretrained='outdoor').to(device).eval()\n",
    "    if device.type == 'cuda':\n",
    "        model = model.half()\n",
    "    return model, device\n",
    "\n",
    "loftr_model, device = load_loftr()\n",
    "use_half = device.type == 'cuda'\n",
    "\n",
    "# LoFTR stitching logic\n",
    "@torch.inference_mode()\n",
    "def stitch_with_loftr(img1_bgr, img2_bgr):\n",
    "    img1_gray = cv2.cvtColor(img1_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    img2_gray = cv2.cvtColor(img2_bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    tensor1 = K.image_to_tensor(img1_gray, False).to(device)\n",
    "    tensor2 = K.image_to_tensor(img2_gray, False).to(device)\n",
    "\n",
    "    if use_half:\n",
    "        tensor1 = tensor1.half() / 255.0\n",
    "        tensor2 = tensor2.half() / 255.0\n",
    "    else:\n",
    "        tensor1 = tensor1.float() / 255.0\n",
    "        tensor2 = tensor2.float() / 255.0\n",
    "\n",
    "    batch = {\"image0\": tensor1, \"image1\": tensor2}\n",
    "    output = loftr_model(batch)\n",
    "\n",
    "    mkpts0 = output['keypoints0'].cpu().numpy()\n",
    "    mkpts1 = output['keypoints1'].cpu().numpy()\n",
    "\n",
    "    if len(mkpts0) < 4:\n",
    "        return None, \"❌ Not enough matches found.\"\n",
    "\n",
    "    H, _ = cv2.findHomography(mkpts1, mkpts0, cv2.RANSAC, 5.0)\n",
    "    if H is None:\n",
    "        return None, \"❌ Homography estimation failed.\"\n",
    "\n",
    "    return warp_images(img1_bgr, img2_bgr, H), None\n",
    "\n",
    "# Common warping function\n",
    "\n",
    "def warp_images(img1, img2, H):\n",
    "    h1, w1 = img1.shape[:2]\n",
    "    h2, w2 = img2.shape[:2]\n",
    "\n",
    "    corners2 = np.float32([[0, 0], [0, h2], [w2, h2], [w2, 0]]).reshape(-1, 1, 2)\n",
    "    transformed_corners = cv2.perspectiveTransform(corners2, H)\n",
    "    all_corners = np.concatenate((np.float32([[0, 0], [0, h1], [w1, h1], [w1, 0]]).reshape(-1, 1, 2), transformed_corners), axis=0)\n",
    "\n",
    "    [xmin, ymin] = np.int32(all_corners.min(axis=0).ravel() - 0.5)\n",
    "    [xmax, ymax] = np.int32(all_corners.max(axis=0).ravel() + 0.5)\n",
    "\n",
    "    translation = [-xmin, -ymin]\n",
    "    H_translation = np.array([[1, 0, translation[0]], [0, 1, translation[1]], [0, 0, 1]])\n",
    "\n",
    "    panorama = cv2.warpPerspective(img2, H_translation @ H, (xmax - xmin, ymax - ymin))\n",
    "    panorama[translation[1]:h1 + translation[1], translation[0]:w1 + translation[0]] = img1\n",
    "\n",
    "    return panorama\n",
    "\n",
    "# SIFT-based stitching logic\n",
    "def stitch_with_sift(img1, img2):\n",
    "    gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    octaves1 = generate_image_pyramid(gray1)\n",
    "    octaves2 = generate_image_pyramid(gray2)\n",
    "    dog1 = calculate_dog(octaves1)\n",
    "    dog2 = calculate_dog(octaves2)\n",
    "\n",
    "    kp1 = SIFT_feature_detection(dog1, gray1)\n",
    "    kp2 = SIFT_feature_detection(dog2, gray2)\n",
    "\n",
    "    cv2_kp1 = convert_keypoints_to_cv2(kp1)\n",
    "    cv2_kp2 = convert_keypoints_to_cv2(kp2)\n",
    "    kp1, desc1 = get_descriptors(gray1, cv2_kp1)\n",
    "    kp2, desc2 = get_descriptors(gray2, cv2_kp2)\n",
    "\n",
    "    matches = match_keypoints(desc1, desc2)\n",
    "    if len(matches) < 4:\n",
    "        return None, \"❌ Not enough matches.\"\n",
    "\n",
    "    src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "\n",
    "    H, _ = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC, 5.0)\n",
    "    if H is None:\n",
    "        return None, \"❌ Homography computation failed.\"\n",
    "\n",
    "    return warp_images(img1, img2, H), None\n",
    "\n",
    "# ------------------------ Streamlit Frontend ------------------------ #\n",
    "st.set_page_config(layout=\"wide\")\n",
    "st.title(\"📸 Image Stitching: SIFT vs LoFTR\")\n",
    "st.markdown(\"Upload LEFT and RIGHT images, and select your preferred stitching method.\")\n",
    "\n",
    "method = st.radio(\"Choose a method:\", [\"SIFT\", \"LoFTR\", \"Both\"], horizontal=True)\n",
    "\n",
    "left_file = st.file_uploader(\"Upload LEFT image\", type=[\"jpg\", \"jpeg\", \"png\"], key=\"left\")\n",
    "right_file = st.file_uploader(\"Upload RIGHT image\", type=[\"jpg\", \"jpeg\", \"png\"], key=\"right\")\n",
    "\n",
    "def load_image(file):\n",
    "    img = Image.open(file).convert(\"RGB\")\n",
    "    return cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "if left_file and right_file:\n",
    "    img1 = load_image(left_file)\n",
    "    img2 = load_image(right_file)\n",
    "    st.success(\"✅ Images loaded successfully!\")\n",
    "\n",
    "    if st.button(\"🧵 Stitch Images\"):\n",
    "        if method == \"SIFT\":\n",
    "            with st.spinner(\"Stitching using SIFT...\"):\n",
    "                result, error = stitch_with_sift(img1, img2)\n",
    "\n",
    "        elif method == \"LoFTR\":\n",
    "            with st.spinner(\"Stitching using LoFTR (deep learning)...\"):\n",
    "                result, error = stitch_with_loftr(img1, img2)\n",
    "\n",
    "        elif method == \"Both\":\n",
    "            col1, col2 = st.columns(2)\n",
    "            with st.spinner(\"Running both methods...\"):\n",
    "                res_sift, err1 = stitch_with_sift(img1, img2)\n",
    "                res_loftr, err2 = stitch_with_loftr(img1, img2)\n",
    "\n",
    "            if res_sift is not None:\n",
    "                col1.image(cv2.cvtColor(res_sift, cv2.COLOR_BGR2RGB), caption=\"SIFT Panorama\", use_column_width=True)\n",
    "            else:\n",
    "                col1.error(err1)\n",
    "\n",
    "            if res_loftr is not None:\n",
    "                col2.image(cv2.cvtColor(res_loftr, cv2.COLOR_BGR2RGB), caption=\"LoFTR Panorama\", use_column_width=True)\n",
    "            else:\n",
    "                col2.error(err2)\n",
    "            st.stop()\n",
    "\n",
    "        if result is not None:\n",
    "            st.image(cv2.cvtColor(result, cv2.COLOR_BGR2RGB), caption=f\"🧵 Final Panorama ({method})\", use_column_width=True)\n",
    "        else:\n",
    "            st.error(error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0606a02-12a7-4f7f-b5f5-dc6405e18b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
